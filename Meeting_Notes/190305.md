# Meeting notes

## 5th March 2019

### List of actions completed

- Made the analysis functions genralised to CNN and Supermodel.
- Investigated the models' accuracy, confidence and ROCs for different cloud types as defined by the CALIOP file. Low accuracy for the broken clouds may be due to the time difference between CALIOP and SLSTR data.
- Tried to do the same with the 'clear' subtypes but no aerosols were picked up by CALIOP in the dataset.
- Created confidence plots for surface types as well.

![Ctype_accuracy](http://www.hep.ph.ic.ac.uk/~kt2015/ctype_accuracy.png)
Accuracy is defined as the number of model outputs that agree with CALIOP over the total number of points. We are using the 1km CALIOP data where we sort through the data for which surface type bitmask is set to 2 (see 'Feature_Classification_Flags' header).

![Cloudy_confidences](http://www.hep.ph.ic.ac.uk/~kt2015/conf_ctype_cloud.png)

![Clear_confidences](http://www.hep.ph.ic.ac.uk/~kt2015/conf_ctype_clear.png)

![N_ctypes](http://www.hep.ph.ic.ac.uk/~kt2015/N_ctype.png)

![Stype_cloudy_confidences](http://www.hep.ph.ic.ac.uk/~kt2015/confidence_stype_cloudy.png)

![Stype_clear_confidences](http://www.hep.ph.ic.ac.uk/~kt2015/confidence_stype_clear.png)

### Questions

- Would it be more useful to have a table with these values in a table rather than histograms?
- Would be worth giving the number of data points in each category?